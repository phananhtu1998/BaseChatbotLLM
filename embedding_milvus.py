from pymilvus import (
    connections, Collection, CollectionSchema, FieldSchema, DataType, utility, Index
)
from sentence_transformers import SentenceTransformer
from spacy.lang.vi import Vietnamese
import uuid

# 1. K·∫øt n·ªëi t·ªõi Milvus
connections.connect("default", host="localhost", port="19530")

collection_name = "chatbot_docs"

# 2. ƒê·ªçc d·ªØ li·ªáu v√† t√°ch c√¢u v·ªõi spaCy
nlp = Vietnamese()
nlp.add_pipe("sentencizer")
with open("data.txt", "r", encoding="utf-8") as f:
    raw_text = f.read()
doc = nlp(raw_text)
sentences = [sent.text.strip() for sent in doc.sents if sent.text.strip()]

# 3. T·∫°o embedding
model = SentenceTransformer("all-MiniLM-L6-v2")
embeddings = model.encode(sentences)

# 4. T·∫°o schema
text_id_field = FieldSchema(
    name="id", dtype=DataType.VARCHAR, is_primary=True, auto_id=False, max_length=36
)
text_field = FieldSchema(
    name="text", dtype=DataType.VARCHAR, max_length=2048
)
vector_field = FieldSchema(
    name="embedding", dtype=DataType.FLOAT_VECTOR, dim=len(embeddings[0])
)
schema = CollectionSchema(
    fields=[text_id_field, text_field, vector_field],
    description="Text embeddings for chatbot"
)

# 5. T·∫°o collection n·∫øu ch∆∞a c√≥
if not utility.has_collection(collection_name):
    collection = Collection(name=collection_name, schema=schema)
    print(f"‚úÖ ƒê√£ t·∫°o collection '{collection_name}'")
else:
    collection = Collection(collection_name)
    print(f"‚ÑπÔ∏è Collection '{collection_name}' ƒë√£ t·ªìn t·∫°i")

# 6. Chu·∫©n b·ªã d·ªØ li·ªáu ch√®n (l·ªçc c√¢u d√†i <= 512 k√Ω t·ª±)
filtered_sentences = []
filtered_embeddings = []
ids = []

for i, sent in enumerate(sentences):
    if len(sent) <= 512:
        filtered_sentences.append(sent)
        filtered_embeddings.append(embeddings[i].tolist())
        ids.append(str(uuid.uuid4()))
    else:
        print(f"‚ö†Ô∏è B·ªè qua c√¢u qu√° d√†i ({len(sent)}): {sent[:60]}...")

data = [ids, filtered_sentences, filtered_embeddings]

# 7. Ch√®n d·ªØ li·ªáu
insert_result = collection.insert(data)
collection.flush()
print(f"‚úÖ ƒê√£ ch√®n {len(filtered_sentences)} b·∫£n ghi v√†o collection")

# 8. T·∫°o index n·∫øu ch∆∞a c√≥
if not collection.has_index():
    index_params = {
        "index_type": "IVF_FLAT",
        "metric_type": "IP",  # ho·∫∑c "L2" n·∫øu b·∫°n d√πng L2 distance
        "params": {"nlist": 128}
    }
    collection.create_index(field_name="embedding", index_params=index_params)
    print("‚úÖ ƒê√£ t·∫°o index cho collection")

print("üéâ Ho√†n th√†nh chu·∫©n b·ªã d·ªØ li·ªáu v√† index.")
