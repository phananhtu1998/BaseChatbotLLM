import re
import time
import random
from typing import List
from datetime import datetime
from urllib.parse import quote_plus
import requests
from bs4 import BeautifulSoup
from .models import SearchResult, RankedResult
from .reranker import ContentReranker
from .gemini_api import GeminiAPI

class SearchInterface:
    def __init__(self, api_key: str, model: str = "gemini-2.0-flash"):
        self.reranker = ContentReranker()
        self.search_history = []
        self.gemini_api = GeminiAPI(api_key, model)
        self.session = requests.Session()
        self.session.headers.update({
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
            'Accept-Language': 'en-US,en;q=0.5',
            'Accept-Encoding': 'gzip, deflate',
            'Connection': 'keep-alive',
            'Upgrade-Insecure-Requests': '1',
        })
        self.cache = {}
        # ThÃªm thÃ´ng tin thá»i gian
        self.current_date = datetime.now().strftime("%d/%m/%Y")
        self.llm_training_cutoff = "thÃ¡ng 6/2024"  # Thá»i Ä‘iá»ƒm model Ä‘Æ°á»£c train Ä‘áº¿n

    def search_bing(self, query: str, max_results: int = 10) -> List[SearchResult]:
        """TÃ¬m kiáº¿m káº¿t quáº£ tá»« Bing (á»•n Ä‘á»‹nh vÃ  dá»… scrape)."""
        retries = 3
        backoff_factor = 5

        for attempt in range(retries):
            try:
                time.sleep(random.uniform(2, 5))
                encoded_query = quote_plus(query)
                search_url = f"https://www.bing.com/search?q={encoded_query}"

                print(f"ğŸŒ Äang tÃ¬m kiáº¿m trÃªn Bing: {query}")

                headers = {
                    "User-Agent": (
                        "Mozilla/5.0 (Windows NT 10.0; Win64; x64) "
                        "AppleWebKit/537.36 (KHTML, like Gecko) "
                        "Chrome/124.0.0.0 Safari/537.36"
                    )
                }

                response = requests.get(search_url, headers=headers, timeout=15)
                response.raise_for_status()

                soup = BeautifulSoup(response.text, 'html.parser')
                results = []

                result_blocks = soup.select("li.b_algo")

                for block in result_blocks[:max_results]:
                    try:
                        title_elem = block.find("h2")
                        link_elem = title_elem.find("a") if title_elem else None
                        desc_elem = block.find("p")

                        if not link_elem or not link_elem.get("href", "").startswith("http"):
                            continue

                        title = title_elem.get_text().strip()
                        url = link_elem["href"]
                        description = desc_elem.get_text().strip() if desc_elem else ""

                        content = self.scrape_content(url)

                        results.append(SearchResult(
                            title=title,
                            url=url,
                            description=description,
                            content=content,
                            source="Bing"
                        ))
                        print(f"âœ… Bing - TÃ¬m tháº¥y: {title}")

                    except Exception as e:
                        print(f"âš ï¸ Lá»—i parse Bing result: {e}")
                        continue

                print(f"ğŸ” Bing hoÃ n thÃ nh: {len(results)} káº¿t quáº£")
                return results

            except Exception as e:
                print(f"âŒ Lá»—i Bing search: {e}")
                time.sleep(backoff_factor * (2 ** attempt))

        print("âŒ Bing search tháº¥t báº¡i sau nhiá»u láº§n thá»­.")
        return []



    def detect_time_sensitive_query(self, query: str) -> bool:
        """PhÃ¡t hiá»‡n cÃ¢u há»i liÃªn quan Ä‘áº¿n thá»i gian hiá»‡n táº¡i."""
        time_keywords = [
            'tuá»•i', 'age', 'nÄƒm nay', 'hiá»‡n táº¡i', 'bÃ¢y giá»', 'hÃ´m nay', 'today', 'now', 'current',
            'má»›i nháº¥t', 'latest', 'recent', 'gáº§n Ä‘Ã¢y', '2024', '2025', 'this year',
            'tin tá»©c', 'news', 'cáº­p nháº­t', 'update', 'thá»i sá»±'
        ]
        
        query_lower = query.lower()
        return any(keyword in query_lower for keyword in time_keywords)

    def add_time_context_to_prompt(self, original_prompt: str, query: str) -> str:
        """ThÃªm context thá»i gian vÃ o prompt cho LLM."""
        if self.detect_time_sensitive_query(query):
            time_context = f"""
            QUAN TRá»ŒNG - THÃ”NG TIN THá»œI GIAN:
            - NgÃ y hiá»‡n táº¡i: {self.current_date} (30/5/2025)
            - Model Ä‘Æ°á»£c train Ä‘áº¿n: {self.llm_training_cutoff} (thÃ¡ng 6/2024)
            - Khi tráº£ lá»i cÃ¢u há»i vá» tuá»•i, thá»i gian, sá»± kiá»‡n hiá»‡n táº¡i, hÃ£y sá»­ dá»¥ng thÃ´ng tin tá»« search results Ä‘á»ƒ cáº­p nháº­t Ä‘áº¿n thá»i Ä‘iá»ƒm hiá»‡n táº¡i (2025)
            - Náº¿u khÃ´ng cÃ³ thÃ´ng tin má»›i tá»« search, hÃ£y nÃ³i rÃµ ráº±ng thÃ´ng tin cÃ³ thá»ƒ Ä‘Ã£ lá»—i thá»i

            """
            return time_context + original_prompt
        
        return original_prompt

    def search_duckduckgo(self, query: str, max_results: int = 10) -> List[SearchResult]:
        """TÃ¬m kiáº¿m thá»±c táº¿ vá»›i DuckDuckGo (web scraping)."""
        retries = 3
        backoff_factor = 5
        
        for attempt in range(retries):
            try:
                # ThÃªm delay ngáº«u nhiÃªn Ä‘á»ƒ trÃ¡nh bá»‹ block
                time.sleep(random.uniform(2, 5))
                
                # Encode query cho URL
                encoded_query = quote_plus(query)
                search_url = f"https://duckduckgo.com/html/?q={encoded_query}"
                
                print(f"ğŸŒ Äang tÃ¬m kiáº¿m trÃªn DuckDuckGo: {query}")
                
                # Gá»­i yÃªu cáº§u vá»›i cÃ¡c tham sá»‘ phÃ¹ há»£p
                response = self.session.get(search_url, timeout=15)
                response.raise_for_status()
                
                soup = BeautifulSoup(response.text, 'html.parser')
                results = []
                
                # TÃ¬m cÃ¡c káº¿t quáº£ tÃ¬m kiáº¿m DuckDuckGo
                search_containers = soup.find_all('div', class_='result__body')
                
                for container in search_containers[:max_results]:
                    try:
                        # Láº¥y title
                        title_elem = container.find('a', class_='result__a')
                        if not title_elem:
                            continue
                        title = title_elem.get_text().strip()
                        
                        # Láº¥y URL
                        url = title_elem.get('href')
                        if not url or not url.startswith('http'):
                            continue
                        
                        # Láº¥y description (snippet)
                        desc_elem = container.find('a', class_='result__snippet')
                        description = desc_elem.get_text().strip() if desc_elem else ""
                        
                        if not description:
                            # Fallback: tÃ¬m mÃ´ táº£ trong tháº» khÃ¡c
                            desc_elem = container.find('div', class_='result__snippet')
                            if desc_elem:
                                description = desc_elem.get_text().strip()
                        
                        if title and url:
                            # Scrape ná»™i dung tá»« URL
                            content = self.scrape_content(url)
                            
                            search_result = SearchResult(
                                title=title,
                                url=url,
                                description=description,
                                content=content,
                                source="DuckDuckGo"
                            )
                            results.append(search_result)
                            
                            print(f"âœ… DuckDuckGo - TÃ¬m tháº¥y: {title}")
                    
                    except Exception as e:
                        print(f"âš ï¸ Lá»—i parse DuckDuckGo result: {e}")
                        continue
                
                print(f"ğŸ” DuckDuckGo hoÃ n thÃ nh: {len(results)} káº¿t quáº£")
                return results
            
            except requests.exceptions.HTTPError as e:
                if response.status_code == 429:
                    print(f"âš ï¸ DuckDuckGo 429: QuÃ¡ nhiá»u yÃªu cáº§u. Thá»­ láº¡i sau {backoff_factor * (2 ** attempt)} giÃ¢y...")
                    time.sleep(backoff_factor * (2 ** attempt))
                else:
                    print(f"âŒ Lá»—i DuckDuckGo search: {e}")
                    return []
            except Exception as e:
                print(f"âŒ Lá»—i DuckDuckGo search: {e}")
                return []
    
        print("âŒ DuckDuckGo search tháº¥t báº¡i sau nhiá»u láº§n thá»­.")
        return []

    def search_combined(self, query: str, total_results: int = 10) -> List[SearchResult]:
        """Káº¿t há»£p tÃ¬m kiáº¿m tá»« Bing vÃ  DuckDuckGo."""
        print(f"\nğŸ” Báº¯t Ä‘áº§u tÃ¬m kiáº¿m káº¿t há»£p: '{query}'")
        print("ğŸ“Š Chiáº¿n lÆ°á»£c: Bing (5 káº¿t quáº£) + DuckDuckGo (5 káº¿t quáº£)")
        
        # Chia Ä‘á»u káº¿t quáº£ giá»¯a 2 search engine
        results_per_engine = total_results // 2
        
        all_results = []
        
        # TÃ¬m kiáº¿m song song (cÃ³ thá»ƒ tá»‘i Æ°u vá»›i threading sau)
        ping_results = self.search_bing(query, max_results=results_per_engine)
        duckduckgo_results = self.search_duckduckgo(query, max_results=results_per_engine)
        
        # Káº¿t há»£p káº¿t quáº£
        all_results.extend(ping_results)
        all_results.extend(duckduckgo_results)
        
        # Loáº¡i bá» duplicate URLs
        seen_urls = set()
        unique_results = []
        
        for result in all_results:
            if result.url not in seen_urls:
                seen_urls.add(result.url)
                unique_results.append(result)
        
        print(f"ğŸ¯ Tá»•ng káº¿t: {len(unique_results)} káº¿t quáº£ unique tá»« {len(all_results)} káº¿t quáº£ gá»‘c")
        
        return unique_results[:total_results]  # Giá»›i háº¡n theo yÃªu cáº§u

    def scrape_content(self, url: str, max_length: int = 1500) -> str:
        """Scrape ná»™i dung tá»« URL."""
        try:
            # ThÃªm delay nhá»
            time.sleep(random.uniform(0.5, 1.5))
            
            response = self.session.get(url, timeout=10)
            
            if response.status_code == 200:
                soup = BeautifulSoup(response.text, 'html.parser')
                
                # Loáº¡i bá» script, style, nav, footer
                for tag in soup(["script", "style", "nav", "footer", "header", "aside"]):
                    tag.decompose()
                
                # TÃ¬m ná»™i dung chÃ­nh
                content_selectors = [
                    'article', '.content', '.main-content', '.post-content', 
                    '.entry-content', '#content', 'main', '.article-body', 
                    '.story-body', '.post-body', '.content-body'
                ]
                
                content = ""
                for selector in content_selectors:
                    content_elem = soup.select_one(selector)
                    if content_elem:
                        content = content_elem.get_text(separator=' ', strip=True)
                        break
                
                # Náº¿u khÃ´ng tÃ¬m tháº¥y, láº¥y tá»« body
                if not content:
                    body = soup.find('body')
                    if body:
                        content = body.get_text(separator=' ', strip=True)
                
                # LÃ m sáº¡ch vÃ  giá»›i háº¡n Ä‘á»™ dÃ i
                if content:
                    content = re.sub(r'\s+', ' ', content).strip()
                    return content[:max_length] + "..." if len(content) > max_length else content
            
        except Exception as e:
            print(f"âš ï¸ Lá»—i scrape {url}: {e}")
        
        return ""

    def start_interactive_search(self):
        """Báº¯t Ä‘áº§u phiÃªn tÃ¬m kiáº¿m tÆ°Æ¡ng tÃ¡c."""
        print("=" * 60)
        print("ğŸ” Há»† THá»NG TÃŒM KIáº¾M THÃ”NG MINH Vá»šI GEMINI AI")
        print("=" * 60)
        print("ğŸ’¡ Chá»‰ cáº§n nháº­p cÃ¢u há»i, há»‡ thá»‘ng sáº½ tá»± Ä‘á»™ng:")
        print("   â€¢ TÃ¬m kiáº¿m trÃªn Bing + DuckDuckGo")
        print("   â€¢ Káº¿t há»£p vÃ  loáº¡i bá» trÃ¹ng láº·p")
        print("   â€¢ Sáº¯p xáº¿p káº¿t quáº£ theo Ä‘á»™ liÃªn quan vá»›i Reranker")
        print("   â€¢ Táº¡o cÃ¢u tráº£ lá»i thÃ´ng minh vá»›i Gemini AI")
        print("=" * 60)
        print("Nháº­p 'quit' Ä‘á»ƒ thoÃ¡t | 'history' Ä‘á»ƒ xem lá»‹ch sá»­ | 'help' Ä‘á»ƒ xem hÆ°á»›ng dáº«n")
        print("-" * 60)
        
        while True:
            try:
                query = input("\nğŸ’¬ Há»i gÃ¬ Ä‘Ã³: ").strip()
                
                if not query:
                    print("âš ï¸ Vui lÃ²ng nháº­p cÃ¢u há»i!")
                    continue
                
                if query.lower() in ['quit', 'exit', 'thoÃ¡t']:
                    print("ğŸ‘‹ Cáº£m Æ¡n báº¡n Ä‘Ã£ sá»­ dá»¥ng! Táº¡m biá»‡t!")
                    break
                
                elif query.lower() in ['history', 'lá»‹ch sá»­']:
                    self.show_search_history()
                    continue
                
                elif query.lower() in ['help', 'hÆ°á»›ng dáº«n']:
                    self.show_help()
                    continue
                
                # Thá»±c hiá»‡n tÃ¬m kiáº¿m vÃ  tráº£ lá»i
                self.perform_search(query)
                
                continue_choice = input("\nâ“ Tiáº¿p tá»¥c há»i? (Enter Ä‘á»ƒ tiáº¿p tá»¥c, 'q' Ä‘á»ƒ thoÃ¡t): ").strip()
                if continue_choice.lower() in ['q', 'quit', 'thoÃ¡t']:
                    print("ğŸ‘‹ Cáº£m Æ¡n báº¡n Ä‘Ã£ sá»­ dá»¥ng!")
                    break
                
            except KeyboardInterrupt:
                print("\nğŸ‘‹ Cáº£m Æ¡n báº¡n Ä‘Ã£ sá»­ dá»¥ng! Táº¡m biá»‡t!")
                break
            except Exception as e:
                print(f"âŒ Lá»—i: {e}")
                print("ğŸ”„ Vui lÃ²ng thá»­ láº¡i...")

    def perform_search(self, query: str, total_results: int = 10, top_k: int = 5):
        """Thá»±c hiá»‡n tÃ¬m kiáº¿m káº¿t há»£p vá»›i query."""
        print(f"\nğŸ” Äang tÃ¬m kiáº¿m: '{query}'")
        print("â³ Vui lÃ²ng Ä‘á»£i...")
        
        # LÆ°u vÃ o lá»‹ch sá»­
        self.search_history.append({
            'query': query,
            'timestamp': self.get_current_time()
        })
        
        # TÃ¬m kiáº¿m káº¿t há»£p Bing + DuckDuckGo
        combined_results = self.search_combined(query, total_results=total_results)
        
        if not combined_results:
            print("âŒ KhÃ´ng tÃ¬m tháº¥y káº¿t quáº£ nÃ o! Vui lÃ²ng thá»­ láº¡i sau.")
            return
            
        print(f"âœ… Tá»•ng cá»™ng tÃ¬m tháº¥y {len(combined_results)} káº¿t quáº£ tá»« cáº£ Bing vÃ  DuckDuckGo")
        
        # Rerank vá»›i hybrid method
        print("ğŸ”„ Äang sáº¯p xáº¿p láº¡i káº¿t quáº£ theo Ä‘á»™ liÃªn quan vá»›i Reranker...")
        ranked_results = self.reranker.rerank_hybrid(query, combined_results, top_k)
        
        # Táº¡o context tá»« káº¿t quáº£ Ä‘Ã£ rerank
        search_context = self._format_search_context(ranked_results)
        
        # Gá»i Gemini API Ä‘á»ƒ táº¡o cÃ¢u tráº£ lá»i
        print("ğŸ¤– Äang táº¡o cÃ¢u tráº£ lá»i vá»›i Gemini AI...")
        answer = self._generate_answer_with_gemini(query, search_context)
        
        # Hiá»ƒn thá»‹ káº¿t quáº£ cuá»‘i cÃ¹ng
        self.display_final_answer(query, answer, ranked_results)

    def _format_search_context(self, ranked_results: List[RankedResult]) -> str:
        """Format search context Ä‘á»ƒ gá»­i cho Gemini."""
        if not ranked_results:
            return "KhÃ´ng tÃ¬m tháº¥y thÃ´ng tin liÃªn quan."
        
        context = "THÃ”NG TIN TÃŒM KIáº¾M (ÄÃƒ Sáº®P Xáº¾P THEO Äá»˜ LIÃŠN QUAN - BING + DUCKDUCKGO):\n\n"
        
        for i, ranked in enumerate(ranked_results, 1):
            result = ranked.original_result
            context += f"[Nguá»“n {i} - {result.source}] {result.title}\n"
            context += f"URL: {result.url}\n"
            context += f"MÃ´ táº£: {result.description}\n"
            
            if result.content:
                content = result.content[:800] + "..." if len(result.content) > 800 else result.content
                context += f"Ná»™i dung: {content}\n"
            
            context += f"Äiá»ƒm liÃªn quan: {ranked.combined_score:.2f}\n"
            context += "\n" + "-"*50 + "\n\n"
        
        return context

    def _generate_answer_with_gemini(self, query: str, search_context: str) -> str:
        """Gá»i Gemini API Ä‘á»ƒ táº¡o cÃ¢u tráº£ lá»i vá»›i kháº£ nÄƒng nháº­n diá»‡n vÃ  tráº£ lá»i báº±ng báº¥t ká»³ ngÃ´n ngá»¯ nÃ o."""
    
    # Táº¡o prompt tá»•ng quÃ¡t cho má»i ngÃ´n ngá»¯
        base_prompt = f"""
    Báº¡n lÃ  má»™t trá»£ lÃ½ AI thÃ´ng minh vÃ  Ä‘a ngÃ´n ngá»¯. HÃ£y tráº£ lá»i cÃ¢u há»i dá»±a trÃªn thÃ´ng tin tÃ¬m kiáº¿m Ä‘Æ°á»£c cung cáº¥p.

    CÃ‚U Há»I / QUESTION / ì§ˆë¬¸ / è³ªå• / PREGUNTA / QUESTION / FRAGE / DOMANDA / PERGUNTA / Ğ’ĞĞŸĞ ĞĞ¡ / Ø³Ø¤Ø§Ù„ / à¤ªà¥à¤°à¤¶à¥à¤¨ / å•é¡Œ:
    {query}

    THÃ”NG TIN TÃŒM KIáº¾M / SEARCH CONTEXT / ê²€ìƒ‰ ì»¨í…ìŠ¤íŠ¸ / æ¤œç´¢ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ / CONTEXTO DE BÃšSQUEDA / CONTEXTE DE RECHERCHE / SUCHKONTEXT / CONTESTO DI RICERCA / CONTEXTO DE PESQUISA / ĞšĞĞĞ¢Ğ•ĞšĞ¡Ğ¢ ĞŸĞĞ˜Ğ¡ĞšĞ / Ø³ÙŠØ§Ù‚ Ø§Ù„Ø¨Ø­Ø« / à¤–à¥‹à¤œ à¤¸à¤‚à¤¦à¤°à¥à¤­:
    {search_context}

    HÆ¯á»šNG DáºªN QUAN TRá»ŒNG / CRITICAL INSTRUCTIONS / ì¤‘ìš”í•œ ì§€ì¹¨ / é‡è¦ãªæŒ‡ç¤º / INSTRUCCIONES CRÃTICAS / INSTRUCTIONS CRITIQUES / KRITISCHE ANWEISUNGEN / ISTRUZIONI CRITICHE / INSTRUÃ‡Ã•ES CRÃTICAS / ĞšĞ Ğ˜Ğ¢Ğ˜Ğ§Ğ•Ğ¡ĞšĞ˜Ğ• Ğ˜ĞĞ¡Ğ¢Ğ Ğ£ĞšĞ¦Ğ˜Ğ˜ / ØªØ¹Ù„ÙŠÙ…Ø§Øª Ù‡Ø§Ù…Ø© / à¤®à¤¹à¤¤à¥à¤µà¤ªà¥‚à¤°à¥à¤£ à¤¨à¤¿à¤°à¥à¤¦à¥‡à¤¶:

    1. **NGÃ”N NGá»® TRáº¢ Lá»œI / RESPONSE LANGUAGE**: 
    - PhÃ¡t hiá»‡n ngÃ´n ngá»¯ chÃ­nh cá»§a cÃ¢u há»i vÃ  TRáº¢ Lá»œI Báº°NG CHÃNH XÃC NGÃ”N NGá»® ÄÃ“
    - Detect the primary language of the question and RESPOND IN EXACTLY THAT LANGUAGE
    - ì§ˆë¬¸ì˜ ì£¼ìš” ì–¸ì–´ë¥¼ ê°ì§€í•˜ê³  ì •í™•íˆ ê·¸ ì–¸ì–´ë¡œ ì‘ë‹µí•˜ì„¸ìš”
    - è³ªå•ã®ä¸»è¦è¨€èªã‚’æ¤œå‡ºã—ã€æ­£ç¢ºã«ãã®è¨€èªã§å›ç­”ã—ã¦ãã ã•ã„
    - Detecta el idioma principal de la pregunta y RESPONDE EXACTAMENTE EN ESE IDIOMA
    - DÃ©tectez la langue principale de la question et RÃ‰PONDEZ EXACTEMENT DANS CETTE LANGUE
    - Erkenne die Hauptsprache der Frage und ANTWORTE GENAU IN DIESER SPRACHE
    - Rileva la lingua principale della domanda e RISPONDI ESATTAMENTE IN QUELLA LINGUA
    - Detecte o idioma principal da pergunta e RESPONDA EXATAMENTE NESSE IDIOMA
    - ĞĞ¿Ñ€ĞµĞ´ĞµĞ»Ğ¸Ñ‚Ğµ Ğ¾ÑĞ½Ğ¾Ğ²Ğ½Ğ¾Ğ¹ ÑĞ·Ñ‹Ğº Ğ²Ğ¾Ğ¿Ñ€Ğ¾ÑĞ° Ğ¸ ĞĞ¢Ğ’Ğ•Ğ§ĞĞ™Ğ¢Ğ• Ğ¢ĞĞ§ĞĞ ĞĞ Ğ­Ğ¢ĞĞœ Ğ¯Ğ—Ğ«ĞšĞ•
    - Ø§ÙƒØªØ´Ù Ø§Ù„Ù„ØºØ© Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ© Ù„Ù„Ø³Ø¤Ø§Ù„ ÙˆØ£Ø¬Ø¨ Ø¨Ø§Ù„Ø¶Ø¨Ø· Ø¨ØªÙ„Ùƒ Ø§Ù„Ù„ØºØ©
    - à¤ªà¥à¤°à¤¶à¥à¤¨ à¤•à¥€ à¤®à¥à¤–à¥à¤¯ à¤­à¤¾à¤·à¤¾ à¤•à¤¾ à¤ªà¤¤à¤¾ à¤²à¤—à¤¾à¤à¤‚ à¤”à¤° à¤ à¥€à¤• à¤‰à¤¸à¥€ à¤­à¤¾à¤·à¤¾ à¤®à¥‡à¤‚ à¤‰à¤¤à¥à¤¤à¤° à¤¦à¥‡à¤‚

    2. **PHÃ‚N TÃCH VÃ€ Tá»”NG Há»¢P / ANALYSIS AND SYNTHESIS**:
    - PhÃ¢n tÃ­ch táº¥t cáº£ cÃ¡c nguá»“n thÃ´ng tin Ä‘Æ°á»£c cung cáº¥p
    - Tá»•ng há»£p thÃ´ng tin tá»« nhiá»u nguá»“n Ä‘á»ƒ cÃ³ cÃ¡i nhÃ¬n toÃ n diá»‡n
    - Æ¯u tiÃªn thÃ´ng tin tá»« cÃ¡c nguá»“n Ä‘Ã¡ng tin cáº­y

    3. **TRÃCH DáºªN NGUá»’N / SOURCE CITATION**:
    - TrÃ­ch dáº«n nguá»“n khi Ä‘Æ°a ra thÃ´ng tin quan trá»ng
    - Sá»­ dá»¥ng format phÃ¹ há»£p vá»›i ngÃ´n ngá»¯ tráº£ lá»i:
        * Tiáº¿ng Viá»‡t: "Theo nguá»“n tá»« [tÃªn nguá»“n]..."
        * English: "According to [source name]..."
        * í•œêµ­ì–´: "[ì†ŒìŠ¤ ì´ë¦„]ì— ë”°ë¥´ë©´..."
        * æ—¥æœ¬èª: "[ã‚½ãƒ¼ã‚¹å]ã«ã‚ˆã‚‹ã¨..."
        * EspaÃ±ol: "SegÃºn [nombre de la fuente]..."
        * FranÃ§ais: "Selon [nom de la source]..."
        * Deutsch: "Laut [Quellenname]..."
        * Italiano: "Secondo [nome della fonte]..."
        * PortuguÃªs: "De acordo com [nome da fonte]..."
        * Ğ ÑƒÑÑĞºĞ¸Ğ¹: "ĞŸĞ¾ Ğ´Ğ°Ğ½Ğ½Ñ‹Ğ¼ [Ğ½Ğ°Ğ·Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ¸ÑÑ‚Ğ¾Ñ‡Ğ½Ğ¸ĞºĞ°]..."
        * Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©: "ÙˆÙÙ‚Ø§Ù‹ Ù„Ù€ [Ø§Ø³Ù… Ø§Ù„Ù…ØµØ¯Ø±]..."
        * à¤¹à¤¿à¤‚à¤¦à¥€: "[à¤¸à¥à¤°à¥‹à¤¤ à¤¨à¤¾à¤®] à¤•à¥‡ à¤…à¤¨à¥à¤¸à¤¾à¤°..."

    4. **Xá»¬ LÃ THÃ”NG TIN MÃ‚U THUáºªN / HANDLING CONTRADICTORY INFORMATION**:
    - Náº¿u cÃ³ thÃ´ng tin mÃ¢u thuáº«n, hÃ£y chá»‰ rÃµ vÃ  Ä‘Æ°a ra phÃ¢n tÃ­ch cÃ¢n báº±ng
    - TrÃ¬nh bÃ y cÃ¡c quan Ä‘iá»ƒm khÃ¡c nhau má»™t cÃ¡ch khÃ¡ch quan

    5. **Cáº¤U TRÃšC CÃ‚U TRáº¢ Lá»œI / ANSWER STRUCTURE**:
    - TrÃ¬nh bÃ y cÃ¢u tráº£ lá»i cÃ³ cáº¥u trÃºc logic, dá»… hiá»ƒu
    - Sá»­ dá»¥ng vÄƒn phong tá»± nhiÃªn cá»§a ngÃ´n ngá»¯ Ä‘Ã­ch
    - Äáº£m báº£o cÃ¢u tráº£ lá»i Ä‘áº§y Ä‘á»§ vÃ  trá»±c tiáº¿p

    6. **TÃNH CHÃNH XÃC / ACCURACY**:
    - Chá»‰ Ä‘Æ°a ra thÃ´ng tin cÃ³ cÄƒn cá»© tá»« cÃ¡c nguá»“n tÃ¬m kiáº¿m
    - Náº¿u thÃ´ng tin khÃ´ng Ä‘áº§y Ä‘á»§, hÃ£y nÃ³i rÃµ Ä‘iá»u Ä‘Ã³
    - TrÃ¡nh Ä‘Æ°a ra thÃ´ng tin sai lá»‡ch hoáº·c khÃ´ng cÃ³ cÄƒn cá»©

    7. **NGÃ”N NGá»® Tá»° NHIÃŠN / NATURAL LANGUAGE**:
    - Sá»­ dá»¥ng ngá»¯ phÃ¡p vÃ  tá»« vá»±ng chÃ­nh xÃ¡c cá»§a ngÃ´n ngá»¯ Ä‘Ã­ch
    - Äáº£m báº£o cÃ¢u tráº£ lá»i nghe tá»± nhiÃªn nhÆ° ngÆ°á»i báº£n ngá»¯
    - TÃ´n trá»ng vÄƒn hÃ³a vÃ  phong cÃ¡ch giao tiáº¿p cá»§a ngÃ´n ngá»¯ Ä‘Ã³

    **LÆ¯U Ã QUAN TRá»ŒNG**: ÄÃ¢y lÃ  yÃªu cáº§u tuyá»‡t Ä‘á»‘i - Báº®T BUá»˜C pháº£i tráº£ lá»i báº±ng chÃ­nh xÃ¡c ngÃ´n ngá»¯ cá»§a cÃ¢u há»i. KhÃ´ng Ä‘Æ°á»£c tráº£ lá»i báº±ng ngÃ´n ngá»¯ khÃ¡c.

    CÃ‚U TRáº¢ Lá»œI / ANSWER / ë‹µë³€ / å›ç­” / RESPUESTA / RÃ‰PONSE / ANTWORT / RISPOSTA / RESPOSTA / ĞĞ¢Ğ’Ğ•Ğ¢ / Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø© / à¤‰à¤¤à¥à¤¤à¤°:
    """
        
        # ThÃªm time context náº¿u cáº§n
        enhanced_prompt = self.add_time_context_to_prompt(base_prompt, query)
        
        return self.gemini_api.generate_answer(enhanced_prompt)

    def display_final_answer(self, query: str, answer: str, ranked_results: List[RankedResult]):
        """Hiá»ƒn thá»‹ cÃ¢u tráº£ lá»i cuá»‘i cÃ¹ng."""
        print("\n" + "="*70)
        print("ğŸ¯ CÃ‚U TRáº¢ Lá»œI CHO CÃ‚U Há»I Cá»¦A Báº N")
        print("="*70)
        print(f"â“ CÃ¢u há»i: {query}")
        print("-"*70)
        print("ğŸ¤– Tráº£ lá»i tá»« Gemini AI:")
        print(answer)
        print("-"*70)
        
        # Hiá»ƒn thá»‹ nguá»“n tham kháº£o vá»›i thÃ´ng tin search engine
        print("ğŸ“š Nguá»“n tham kháº£o (Bing + DuckDuckGo):")
        for i, ranked in enumerate(ranked_results, 1):
            result = ranked.original_result
            print(f"  {i}. [{result.source}] {result.title}")
            print(f"     {result.url}")
            print(f"     Äá»™ tin cáº­y: {ranked.combined_score:.1%}")
        
        print("="*70)

    def show_search_history(self):
        """Hiá»ƒn thá»‹ lá»‹ch sá»­ tÃ¬m kiáº¿m."""
        if not self.search_history:
            print("ğŸ“ ChÆ°a cÃ³ lá»‹ch sá»­ tÃ¬m kiáº¿m nÃ o!")
            return
        
        print("\n" + "="*50)
        print("ğŸ“š Lá»ŠCH Sá»¬ TÃŒM KIáº¾M")
        print("="*50)
        
        for i, item in enumerate(self.search_history[-10:], 1):
            print(f"{i}. '{item['query']}' - {item['timestamp']}")

    def show_help(self):
        """Hiá»ƒn thá»‹ hÆ°á»›ng dáº«n sá»­ dá»¥ng."""
        print("\n" + "="*50)
        print("ğŸ“– HÆ¯á»šNG DáºªN Sá»¬ Dá»¤NG")
        print("="*50)
        print("ğŸ”¹ Nháº­p cÃ¢u há»i báº¥t ká»³ Ä‘á»ƒ Ä‘Æ°á»£c tráº£ lá»i bá»Ÿi Gemini AI")
        print("ğŸ”¹ Nháº­p 'quit' hoáº·c 'thoÃ¡t' Ä‘á»ƒ thoÃ¡t")
        print("ğŸ”¹ Nháº­p 'history' hoáº·c 'lá»‹ch sá»­' Ä‘á»ƒ xem lá»‹ch sá»­")
        print("ğŸ”¹ Nháº­p 'help' hoáº·c 'hÆ°á»›ng dáº«n' Ä‘á»ƒ xem hÆ°á»›ng dáº«n nÃ y")
        print("\nâš™ï¸ Há»‡ thá»‘ng tá»± Ä‘á»™ng:")
        print("â€¢ TÃ¬m kiáº¿m káº¿t há»£p trÃªn Bing + DuckDuckGo (má»—i engine 5 káº¿t quáº£)")
        print("â€¢ Loáº¡i bá» URL trÃ¹ng láº·p giá»¯a cÃ¡c search engine")
        print("â€¢ Scrape ná»™i dung tá»« cÃ¡c trang web")
        print("â€¢ Sáº¯p xáº¿p káº¿t quáº£ theo Ä‘á»™ liÃªn quan (Hybrid Reranking)")
        print("â€¢ Táº¡o cÃ¢u tráº£ lá»i thÃ´ng minh vá»›i Gemini AI")
        print("\nğŸ’¡ VÃ­ dá»¥ cÃ¢u há»i:")
        print("â€¢ 'Python lÃ  gÃ¬ vÃ  táº¡i sao nÃªn há»c?'")
        print("â€¢ 'CÃ¡ch há»c machine learning hiá»‡u quáº£'")
        print("â€¢ 'Xu hÆ°á»›ng cÃ´ng nghá»‡ AI 2024'")
        print("â€¢ 'Lá»£i Ã­ch cá»§a viá»‡c táº­p thá»ƒ dá»¥c'")
        print("\nâš ï¸ LÆ°u Ã½:")
        print("â€¢ Há»‡ thá»‘ng sá»­ dá»¥ng web scraping, cÃ³ thá»ƒ cháº­m hÆ¡n API")
        print("â€¢ TrÃ¡nh tÃ¬m kiáº¿m quÃ¡ nhiá»u láº§n liÃªn tiáº¿p Ä‘á»ƒ khÃ´ng bá»‹ cháº·n")
        print("â€¢ Káº¿t quáº£ Ä‘Æ°á»£c káº¿t há»£p tá»« cáº£ Bing vÃ  DuckDuckGo")

    def get_current_time(self) -> str:
        """Láº¥y thá»i gian hiá»‡n táº¡i."""
        return datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    def search_with_time_awareness(self, query: str, total_results: int = 10, top_k: int = 5):
        """TÃ¬m kiáº¿m vá»›i kháº£ nÄƒng nháº­n biáº¿t thá»i gian."""
        print(f"\nğŸ” Äang phÃ¢n tÃ­ch cÃ¢u há»i: '{query}'")
        
        # Kiá»ƒm tra náº¿u cÃ¢u há»i liÃªn quan Ä‘áº¿n thá»i gian
        if self.detect_time_sensitive_query(query):
            print("â° PhÃ¡t hiá»‡n cÃ¢u há»i liÃªn quan thá»i gian - sáº½ Æ°u tiÃªn thÃ´ng tin má»›i nháº¥t")
            # ThÃªm tá»« khÃ³a Ä‘á»ƒ tÃ¬m thÃ´ng tin má»›i
            enhanced_query = f"{query} 2024 2025 latest current"
        else:
            enhanced_query = query
        
        # Thá»±c hiá»‡n tÃ¬m kiáº¿m
        self.perform_search(enhanced_query, total_results, top_k)