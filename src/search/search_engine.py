from opensearchpy import OpenSearch
from src.config.config import OPENSEARCH_CONFIG, INDEX_NAME, SEARCH_TOP_K, RERANK_TOP_K, FINAL_TOP_K, IMPORTANT_KEYWORDS
from src.models.embedding_models import model, reranker
from src.utils.text_processing import preprocess_text
import re

# Initialize OpenSearch client
client = OpenSearch(**OPENSEARCH_CONFIG)

def keyword_relevance_score(query, doc):
    """T√≠nh ƒëi·ªÉm relevance d·ª±a tr√™n t·ª´ kh√≥a"""
    query_lower = query.lower()
    doc_lower = doc.lower()
    
    score = 0
    
    # T√¨m t√™n ng∆∞·ªùi
    names = re.findall(r'\b[A-Z√Ä√Å·∫¢√É·∫†√Ç·∫¶·∫§·∫®·∫™·∫¨√ä·ªÄ·∫æ·ªÇ·ªÑ·ªÜ√î·ªí·ªê·ªî·ªñ·ªò∆Ø·ª™·ª®·ª¨·ªÆ·ª∞ƒê][a-z√†√°·∫£√£·∫°√¢·∫ß·∫•·∫©·∫´·∫≠√™·ªÅ·∫ø·ªÉ·ªÖ·ªá√¥·ªì·ªë·ªï·ªó·ªô∆∞·ª´·ª©·ª≠·ªØ·ª±ƒë]+(?:\s+[A-Z√Ä√Å·∫¢√É·∫†√Ç·∫¶·∫§·∫®·∫™·∫¨√ä·ªÄ·∫æ·ªÇ·ªÑ·ªÜ√î·ªí·ªê·ªî·ªñ·ªò∆Ø·ª™·ª®·ª¨·ªÆ·ª∞ƒê][a-z√†√°·∫£√£·∫°√¢·∫ß·∫•·∫©·∫´·∫≠√™·ªÅ·∫ø·ªÉ·ªÖ·ªá√¥·ªì·ªë·ªï·ªó·ªô∆∞·ª´·ª©·ª≠·ªØ·ª±ƒë]+)*', query)
    for name in names:
        if name.lower() in doc_lower:
            score += 3
    
    # T√¨m nƒÉm sinh
    years = re.findall(r'\b(19|20)\d{2}\b', query)
    for year in years:
        if year in doc_lower:
            score += 2
    
    # T·ª´ kh√≥a li√™n quan ƒë·∫øn sinh nƒÉm
    if any(word in query_lower for word in ["sinh", "nƒÉm", "born"]):
        if any(word in doc_lower for word in ["sinh", "nƒÉm", "born"]):
            score += 1
    
    # C√°c t·ª´ kh√≥a quan tr·ªçng kh√°c
    for keyword in IMPORTANT_KEYWORDS:
        if keyword in query_lower and keyword in doc_lower:
            score += 1
    
    return score

def search_similar(query_text, top_k=SEARCH_TOP_K):
    """T√¨m ki·∫øm k·∫øt h·ª£p vector similarity v√† text search"""
    
    # Ti·ªÅn x·ª≠ l√Ω query
    processed_query = preprocess_text(query_text)
    
    # T·∫°o embedding cho query
    query_embedding = model.encode([processed_query])[0].tolist()
    
    # T√¨m ki·∫øm k·∫øt h·ª£p KNN v√† text search
    search_query = {
        "size": top_k,
        "query": {
            "bool": {
                "should": [
                    {
                        "knn": {
                            "embedding": {
                                "vector": query_embedding,
                                "k": top_k
                            }
                        }
                    },
                    {
                        "match": {
                            "text": {
                                "query": processed_query,
                                "boost": 0.5
                            }
                        }
                    },
                    {
                        "match_phrase": {
                            "text": {
                                "query": processed_query,
                                "boost": 1.0
                            }
                        }
                    }
                ],
                "minimum_should_match": 1
            }
        },
        "_source": ["text", "chunk_index", "length"]
    }
    
    try:
        response = client.search(index=INDEX_NAME, body=search_query)
        hits = response["hits"]["hits"]
        
        # L·∫•y text v√† ti·ªÅn x·ª≠ l√Ω
        docs_with_score = []
        for hit in hits:
            text = preprocess_text(hit["_source"]["text"])
            score = hit["_score"]
            docs_with_score.append((text, score))
        
        # S·∫Øp x·∫øp theo score
        docs_with_score.sort(key=lambda x: x[1], reverse=True)
        docs = [doc for doc, score in docs_with_score]
        
        print(f"üîç T√¨m th·∫•y {len(docs)} documents")
        return docs
        
    except Exception as e:
        print(f"‚ùå L·ªói search: {e}")
        # Fallback v·ªÅ KNN search ƒë∆°n gi·∫£n
        return search_knn_only(query_text, top_k)

def search_knn_only(query_text, top_k=SEARCH_TOP_K):
    """Fallback: ch·ªâ s·ª≠ d·ª•ng KNN search"""
    processed_query = preprocess_text(query_text)
    query_embedding = model.encode([processed_query])[0].tolist()
    
    search_query = {
        "size": top_k,
        "query": {
            "knn": {
                "embedding": {
                    "vector": query_embedding,
                    "k": top_k
                }
            }
        },
        "_source": ["text"]
    }
    
    try:
        response = client.search(index=INDEX_NAME, body=search_query)
        hits = response["hits"]["hits"]
        docs = [preprocess_text(hit["_source"]["text"]) for hit in hits]
        print(f"üîç KNN Fallback: T√¨m th·∫•y {len(docs)} documents")
        return docs
    except Exception as e:
        print(f"‚ùå L·ªói KNN search: {e}")
        return []

def rerank_docs(query, docs, top_k=RERANK_TOP_K):
    """C·∫£i thi·ªán reranking v·ªõi k·∫øt h·ª£p keyword matching v√† cross-encoder"""
    
    if not docs:
        return []
    
    # B∆∞·ªõc 1: L·ªçc theo keyword relevance
    keyword_scores = [(doc, keyword_relevance_score(query, doc)) for doc in docs]
    keyword_scores.sort(key=lambda x: x[1], reverse=True)
    
    # L·∫•y top docs c√≥ keyword relevance cao
    high_keyword_docs = [doc for doc, score in keyword_scores[:15] if score > 0]
    remaining_docs = [doc for doc, score in keyword_scores if score == 0][:10]
    
    # K·∫øt h·ª£p
    docs_to_rerank = high_keyword_docs + remaining_docs
    
    # B∆∞·ªõc 2: S·ª≠ d·ª•ng cross-encoder cho reranking
    if len(docs_to_rerank) == 0:
        docs_to_rerank = docs[:15]
    
    try:
        pairs = [[query, doc] for doc in docs_to_rerank]
        cross_scores = reranker.predict(pairs)
        
        # K·∫øt h·ª£p ƒëi·ªÉm keyword v√† cross-encoder
        final_scores = []
        for i, (doc, cross_score) in enumerate(zip(docs_to_rerank, cross_scores)):
            keyword_score = keyword_relevance_score(query, doc)
            # Tr·ªçng s·ªë: 70% cross-encoder, 30% keyword
            final_score = 0.7 * cross_score + 0.3 * keyword_score
            final_scores.append((doc, final_score, keyword_score, cross_score))
        
        final_scores.sort(key=lambda x: x[1], reverse=True)
        
        # Debug info
        print(f"üìä Reranking scores:")
        for i, (doc, final_score, kw_score, cross_score) in enumerate(final_scores[:5], 1):
            print(f"  {i}. Final: {final_score:.3f} (KW: {kw_score}, Cross: {cross_score:.3f}) - {doc[:80]}...")
        
        return [doc for doc, _, _, _ in final_scores[:top_k]]
    
    except Exception as e:
        print(f"‚ùå Reranker error: {e}")
        # Fallback v·ªÅ keyword ranking
        return [doc for doc, score in keyword_scores[:top_k]] 