import asyncio
import json
import uuid
from datetime import datetime
from typing import List, Dict, Optional, Any
import logging
from bs4 import BeautifulSoup
import redis.asyncio as redis
import os
import signal
import sys
from dataclasses import dataclass, asdict
from dataclasses_json import dataclass_json
import aiohttp
import re
from urllib.parse import quote_plus
import html

# Install required packages:
# pip install redis google-generativeai dataclasses-json aiohttp beautifulsoup4 python-dotenv

import google.generativeai as genai
from dotenv import load_dotenv
load_dotenv()

# Logging setup
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

@dataclass_json
@dataclass
class ChatMessage:
    role: str  # 'user' or 'assistant'
    content: str
    timestamp: str = None
    search_results: Optional[str] = None  # Store search results
    
    def __post_init__(self):
        if self.timestamp is None:
            self.timestamp = datetime.now().isoformat()

@dataclass_json
@dataclass
class ConversationContext:
    thread_id: str
    user_id: str
    messages: List[ChatMessage] = None
    metadata: Dict[str, Any] = None
    created_at: str = None
    updated_at: str = None
    
    def __post_init__(self):
        if self.messages is None:
            self.messages = []
        if self.metadata is None:
            self.metadata = {}
        now = datetime.now().isoformat()
        if self.created_at is None:
            self.created_at = now
        if self.updated_at is None:
            self.updated_at = now

class DuckDuckGoSearcher:
    """DuckDuckGo search functionality"""
    
    def __init__(self):
        self.session = None
        self.base_url = "https://html.duckduckgo.com/html/"
        
    async def initialize(self):
        """Initialize HTTP session"""
        self.session = aiohttp.ClientSession(
            timeout=aiohttp.ClientTimeout(total=10),
            headers={
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
            }
        )
        
    async def close(self):
        """Close HTTP session"""
        if self.session:
            await self.session.close()
    
    async def search(self, query: str, max_results: int = 5) -> List[Dict[str, str]]:
        """Search DuckDuckGo and return results"""
        try:
            if not self.session:
                await self.initialize()
            
            # Prepare search parameters
            params = {
                'q': query,
                'b': '',  # Start from first result
                'kl': 'wt-wt',  # No region restriction
                'df': '',  # No date filter
            }
            
            logger.info(f"Searching DuckDuckGo for: {query}")
            
            async with self.session.get(self.base_url, params=params) as response:
                if response.status != 200:
                    logger.error(f"DuckDuckGo search failed with status: {response.status}")
                    return []
                
                html_content = await response.text()
                return self._parse_results(html_content, max_results)
                
        except Exception as e:
            logger.error(f"Error searching DuckDuckGo: {e}")
            return []
    
    def _parse_results(self, html_content: str, max_results: int) -> List[Dict[str, str]]:
        """Ph√¢n t√≠ch HTML t·ª´ DuckDuckGo v√† tr√≠ch xu·∫•t k·∫øt qu·∫£ t√¨m ki·∫øm."""
        results = []
        
        try:
            soup = BeautifulSoup(html_content, 'html.parser')
            search_containers = soup.find_all('div', class_='result__body')
            
            for container in search_containers[:max_results]:
                try:
                    # L·∫•y title
                    title_elem = container.find('a', class_='result__a')
                    if not title_elem:
                        continue
                    title = title_elem.get_text().strip()
                    
                    # L·∫•y URL
                    url = title_elem.get('href')
                    if not url or not url.startswith('http'):
                        continue
                    
                    # L·∫•y snippet
                    desc_elem = container.find('a', class_='result__snippet')
                    snippet = desc_elem.get_text().strip() if desc_elem else ""
                    
                    # Fallback: th·ª≠ v·ªõi <div class="result__snippet">
                    if not snippet:
                        desc_elem = container.find('div', class_='result__snippet')
                        if desc_elem:
                            snippet = desc_elem.get_text().strip()
                    
                    if title and snippet:
                        results.append({
                            'title': title,
                            'url': url,
                            'snippet': snippet
                        })

                except Exception as e:
                    logger.warning(f"L·ªói khi ph√¢n t√≠ch k·∫øt qu·∫£ ƒë∆°n l·∫ª: {e}")
                    continue

            logger.info(f"‚úÖ DuckDuckGo - T√¨m ƒë∆∞·ª£c {len(results)} k·∫øt qu·∫£")
        
        except Exception as e:
            logger.error(f"‚ùå L·ªói khi ph√¢n t√≠ch HTML DuckDuckGo: {e}")
        
        return results
    
    def format_search_results(self, results: List[Dict[str, str]]) -> str:
        """Format search results for LLM consumption"""
        if not results:
            return "Kh√¥ng t√¨m th·∫•y k·∫øt qu·∫£ t√¨m ki·∫øm."
        
        formatted = "=== K·∫æT QU·∫¢ T√åM KI·∫æM ===\n\n"
        
        for i, result in enumerate(results, 1):
            formatted += f"{i}. **{result['title']}**\n"
            formatted += f"   {result['snippet']}\n"
            if result['url'].startswith('http'):
                formatted += f"   URL: {result['url']}\n"
            formatted += "\n"
        
        formatted += "=== H·∫æT K·∫æT QU·∫¢ T√åM KI·∫æM ===\n"
        return formatted

class RedisMemoryManager:
    """Redis memory manager for conversation history"""
    
    def __init__(self):
        self.redis_client = None
        self.redis_ttl = 3600  # 1 hour TTL for active sessions
        
    async def initialize(self):
        """Initialize Redis connection"""
        try:
            self.redis_client = redis.Redis(
                host=os.getenv('REDIS_HOST', 'localhost'),
                port=int(os.getenv('REDIS_PORT', 6379)),
                decode_responses=True,
                socket_keepalive=True,
                retry_on_timeout=True
            )
            
            # Test Redis connection
            await self.redis_client.ping()
            logger.info("Redis connection established")
            
        except Exception as e:
            logger.error(f"Failed to initialize Redis: {e}")
            raise
    
    async def close(self):
        """Close Redis connection"""
        if self.redis_client:
            await self.redis_client.aclose()
    
    def _get_redis_key(self, thread_id: str) -> str:
        """Generate Redis key for thread"""
        return f"chat:thread:{thread_id}"
    
    async def get_conversation(self, thread_id: str) -> Optional[ConversationContext]:
        """Get conversation from Redis"""
        try:
            redis_key = self._get_redis_key(thread_id)
            cached_data = await self.redis_client.get(redis_key)
            
            if cached_data:
                logger.info(f"Cache HIT for thread {thread_id}")
                data = json.loads(cached_data)
                
                # Convert message dicts back to ChatMessage objects
                if 'messages' in data and data['messages']:
                    messages = []
                    for msg_data in data['messages']:
                        if isinstance(msg_data, dict):
                            messages.append(ChatMessage(**msg_data))
                        else:
                            messages.append(msg_data)
                    data['messages'] = messages
                
                return ConversationContext(**data)
            
            logger.info(f"Cache MISS for thread {thread_id}")
            return None
            
        except Exception as e:
            logger.error(f"Error getting conversation {thread_id}: {e}")
            return None
    
    async def save_conversation(self, conversation: ConversationContext):
        """Save conversation to Redis"""
        try:
            conversation.updated_at = datetime.now().isoformat()
            
            # Convert to dict for JSON serialization
            data = asdict(conversation)
            
            redis_key = self._get_redis_key(conversation.thread_id)
            await self.redis_client.setex(
                redis_key,
                self.redis_ttl,
                json.dumps(data, default=str)
            )
            
            logger.info(f"Conversation {conversation.thread_id} saved to Redis")
            
        except Exception as e:
            logger.error(f"Error saving conversation {conversation.thread_id}: {e}")
            raise

class HistoryProcessor:
    """X·ª≠ l√Ω l·ªãch s·ª≠ v√† t·∫°o query search th√¥ng minh"""
    
    def __init__(self, model):
        self.model = model
    
    async def process_history_and_input(self, messages: List[ChatMessage], current_input: str) -> Dict[str, Any]:
        """
        X·ª≠ l√Ω l·ªãch s·ª≠ chat v√† input hi·ªán t·∫°i ƒë·ªÉ:
        1. T√≥m t·∫Øt ng·ªØ c·∫£nh quan tr·ªçng
        2. X√°c ƒë·ªãnh c√≥ c·∫ßn search kh√¥ng
        3. T·∫°o query search t·ªëi ∆∞u
        """
        print("üß† ƒêANG X·ª¨ L√ù L·ªäCH S·ª¨ V√Ä INPUT...")
        
        # L·∫•y l·ªãch s·ª≠ g·∫ßn ƒë√¢y (10 tin nh·∫Øn cu·ªëi)
        recent_messages = messages[-10:] if len(messages) > 10 else messages
        
        # T·∫°o summary c·ªßa l·ªãch s·ª≠
        history_summary = self._create_history_summary(recent_messages)
        
        # Ph√¢n t√≠ch input hi·ªán t·∫°i
        input_analysis = await self._analyze_current_input(current_input, history_summary)
        
        # Quy·∫øt ƒë·ªãnh c√≥ c·∫ßn search kh√¥ng
        need_search = input_analysis.get('need_search', False)
        
        # T·∫°o search query n·∫øu c·∫ßn
        search_query = None
        if need_search:
            search_query = input_analysis.get('search_query', current_input)
        
        result = {
            'history_summary': history_summary,
            'input_analysis': input_analysis,
            'need_search': need_search,
            'search_query': search_query,
            'context_for_llm': self._create_context_for_llm(history_summary, current_input)
        }
        
        print(f"üìã K·∫æT QU·∫¢ X·ª¨ L√ù:")
        print(f"   - T√≥m t·∫Øt l·ªãch s·ª≠: {len(history_summary)} k√Ω t·ª±")
        print(f"   - C·∫ßn search: {'C√ì' if need_search else 'KH√îNG'}")
        if search_query:
            print(f"   - Query search: '{search_query}'")
        print()
        
        return result
    
    def _create_history_summary(self, messages: List[ChatMessage]) -> str:
        """T·∫°o t√≥m t·∫Øt l·ªãch s·ª≠ chat"""
        if not messages:
            return "Ch∆∞a c√≥ l·ªãch s·ª≠ tr√≤ chuy·ªán."
        
        # T√≥m t·∫Øt c√°c ch·ªß ƒë·ªÅ ch√≠nh
        topics = []
        entities = []
        
        for msg in messages:
            content = msg.content
            
            # Tr√≠ch xu·∫•t th·ª±c th·ªÉ quan tr·ªçng (t√™n ng∆∞·ªùi, c√¥ng ty, ƒë·ªãa ƒëi·ªÉm)
            # Pattern cho t√™n ng∆∞·ªùi Vi·ªát
            name_pattern = r'([A-Z√Ä√Å·∫†·∫¢√É√Ç·∫¶·∫§·∫¨·∫®·∫™ƒÇ·∫∞·∫Æ·∫∂·∫≤·∫¥√à√â·∫∏·∫∫·∫º√ä·ªÄ·∫æ·ªÜ·ªÇ·ªÑ√å√ç·ªä·ªàƒ®√í√ì·ªå·ªé√ï√î·ªí·ªê·ªò·ªî·ªñ∆†·ªú·ªö·ª¢·ªû·ª†√ô√ö·ª§·ª¶≈®∆Ø·ª™·ª®·ª∞·ª¨·ªÆ·ª≤√ù·ª¥·ª∂·ª∏ƒê][a-z√†√°·∫°·∫£√£√¢·∫ß·∫•·∫≠·∫©·∫´ƒÉ·∫±·∫Ø·∫∑·∫≥·∫µ√®√©·∫π·∫ª·∫Ω√™·ªÅ·∫ø·ªá·ªÉ·ªÖ√¨√≠·ªã·ªâƒ©√≤√≥·ªç·ªè√µ√¥·ªì·ªë·ªô·ªï·ªó∆°·ªù·ªõ·ª£·ªü·ª°√π√∫·ª•·ªß≈©∆∞·ª´·ª©·ª±·ª≠·ªØ·ª≥√Ω·ªµ·ª∑·ªπƒë]+ [A-Z√Ä√Å·∫†·∫¢√É√Ç·∫¶·∫§·∫¨·∫®·∫™ƒÇ·∫∞·∫Æ·∫∂·∫≤·∫¥√à√â·∫∏·∫∫·∫º√ä·ªÄ·∫æ·ªÜ·ªÇ·ªÑ√å√ç·ªä·ªàƒ®√í√ì·ªå·ªé√ï√î·ªí·ªê·ªò·ªî·ªñ∆†·ªú·ªö·ª¢·ªû·ª†√ô√ö·ª§·ª¶≈®∆Ø·ª™·ª®·ª∞·ª¨·ªÆ·ª≤√ù·ª¥·ª∂·ª∏ƒê][a-z√†√°·∫°·∫£√£√¢·∫ß·∫•·∫≠·∫©·∫´ƒÉ·∫±·∫Ø·∫∑·∫≥·∫µ√®√©·∫π·∫ª·∫Ω√™·ªÅ·∫ø·ªá·ªÉ·ªÖ√¨√≠·ªã·ªâƒ©√≤√≥·ªç·ªè√µ√¥·ªì·ªë·ªô·ªï·ªó∆°·ªù·ªõ·ª£·ªü·ª°√π√∫·ª•·ªß≈©∆∞·ª´·ª©·ª±·ª≠·ªØ·ª≥√Ω·ªµ·ª∑·ªπƒë]+)'
            names = re.findall(name_pattern, content)
            entities.extend(names)
            
            # Pattern cho c√¥ng ty/t·ªï ch·ª©c
            company_pattern = r'((?:C√îNG TY|CT|C√îNG TY TNHH|TNHH|JSC|Co\.|Ltd\.|GROUP|THACO|VINGROUP|FPT|VIETTEL)[^.!?\n]*)'
            companies = re.findall(company_pattern, content, re.IGNORECASE)
            entities.extend(companies)
        
        # Lo·∫°i b·ªè tr√πng l·∫∑p v√† l√†m s·∫°ch
        entities = list(set([e.strip() for e in entities if len(e.strip()) > 3]))
        
        # T·∫°o summary
        summary_parts = []
        
        if entities:
            summary_parts.append(f"Th·ª±c th·ªÉ ƒë√£ ƒë·ªÅ c·∫≠p: {', '.join(entities[:5])}")  # L·∫•y 5 th·ª±c th·ªÉ ƒë·∫ßu
        
        # T√≥m t·∫Øt n·ªôi dung ch√≠nh t·ª´ 3 tin nh·∫Øn g·∫ßn nh·∫•t
        recent_content = []
        for msg in messages[-3:]:
            if msg.role == 'user':
                recent_content.append(f"User h·ªèi: {msg.content[:100]}")
            else:
                recent_content.append(f"Bot tr·∫£ l·ªùi v·ªÅ: {msg.content[:100]}")
        
        if recent_content:
            summary_parts.append("N·ªôi dung g·∫ßn ƒë√¢y: " + "; ".join(recent_content))
        
        return ". ".join(summary_parts) if summary_parts else "Cu·ªôc tr√≤ chuy·ªán chung."
    
    async def _analyze_current_input(self, current_input: str, history_summary: str) -> Dict[str, Any]:
        """Ph√¢n t√≠ch input hi·ªán t·∫°i v·ªõi ng·ªØ c·∫£nh l·ªãch s·ª≠"""
        
        # Prompt ƒë·ªÉ ph√¢n t√≠ch input
        analysis_prompt = f"""
H√£y ph√¢n t√≠ch c√¢u h·ªèi sau v·ªõi ng·ªØ c·∫£nh l·ªãch s·ª≠ tr√≤ chuy·ªán:

L·ªäCH S·ª¨ TR√í CHUY·ªÜN: {history_summary}

C√ÇU H·ªéI HI·ªÜN T·∫†I: {current_input}

H√£y tr·∫£ l·ªùi theo format JSON:
{{
    "need_search": true/false,
    "reason": "l√Ω do c·∫ßn/kh√¥ng c·∫ßn search",
    "search_query": "query t√¨m ki·∫øm t·ªëi ∆∞u (n·∫øu c·∫ßn)",
    "resolved_entities": ["danh s√°ch th·ª±c th·ªÉ ƒë√£ ƒë∆∞·ª£c gi·∫£i quy·∫øt t·ª´ l·ªãch s·ª≠"],
    "search_intent": "√Ω ƒë·ªãnh t√¨m ki·∫øm"
}}

Quy t·∫Øc quy·∫øt ƒë·ªãnh:
1. C√ì c·∫ßn search n·∫øu: h·ªèi v·ªÅ th√¥ng tin c·∫≠p nh·∫≠t, tin t·ª©c, gi√° c·∫£, th·ªùi ti·∫øt, s·ª± ki·ªán g·∫ßn ƒë√¢y
2. KH√îNG c·∫ßn search n·∫øu: c√¢u h·ªèi chung, gi·∫£i th√≠ch kh√°i ni·ªám, h·ªèi v·ªÅ l·ªãch s·ª≠, to√°n h·ªçc
3. Khi t·∫°o search query, h√£y thay th·∫ø ƒë·∫°i t·ª´ (√¥ng ·∫•y, b√† ·∫•y, anh ta...) b·∫±ng t√™n c·ª• th·ªÉ t·ª´ l·ªãch s·ª≠
4. ∆Øu ti√™n t·ª´ kh√≥a quan tr·ªçng, lo·∫°i b·ªè t·ª´ d·ª´ng kh√¥ng c·∫ßn thi·∫øt
"""
        
        try:
            # G·ª≠i request t·ªõi Gemini ƒë·ªÉ ph√¢n t√≠ch
            response = await asyncio.to_thread(
                self.model.generate_content, 
                analysis_prompt,
                generation_config=genai.types.GenerationConfig(
                    temperature=0.1,
                    max_output_tokens=500
                )
            )
            
            # Parse JSON response
            analysis_text = response.text.strip()
            
            # T√¨m JSON trong response
            json_match = re.search(r'\{.*\}', analysis_text, re.DOTALL)
            if json_match:
                analysis_json = json.loads(json_match.group())
                print(f"ü§ñ PH√ÇN T√çCH T·ª™ LLM: {analysis_json}")
                return analysis_json
            else:
                print("‚ö†Ô∏è Kh√¥ng parse ƒë∆∞·ª£c JSON, d√πng fallback logic")
                return self._fallback_analysis(current_input)
                
        except Exception as e:
            print(f"‚ùå L·ªói ph√¢n t√≠ch LLM: {e}, d√πng fallback logic")
            return self._fallback_analysis(current_input)
    
    def _fallback_analysis(self, current_input: str) -> Dict[str, Any]:
        """Logic fallback khi LLM analysis fail"""
        # Keywords suggest search is needed
        search_keywords = [
            'tin t·ª©c', 'news', 'm·ªõi nh·∫•t', 'hi·ªán t·∫°i', 'c·∫≠p nh·∫≠t',
            'th·ªùi ti·∫øt', 'weather', 'gi√°', 'price', 't·ª∑ gi√°',
            's·ª± ki·ªán', 'event', 'l·ªãch', 'schedule', 'th√¥ng tin',
            'h√¥m nay', 'today', 'b√¢y gi·ªù', 'now', 'real-time'
        ]
        
        input_lower = current_input.lower()
        found_keywords = [kw for kw in search_keywords if kw in input_lower]
        need_search = len(found_keywords) > 0
        
        return {
            'need_search': need_search,
            'reason': f"Ph√°t hi·ªán t·ª´ kh√≥a: {', '.join(found_keywords)}" if need_search else "Kh√¥ng c√≥ t·ª´ kh√≥a c·∫ßn search",
            'search_query': current_input if need_search else None,
            'resolved_entities': [],
            'search_intent': 'general_search' if need_search else 'knowledge_query'
        }
    
    def _create_context_for_llm(self, history_summary: str, current_input: str) -> str:
        """T·∫°o context t·ªïng h·ª£p ƒë·ªÉ g·ª≠i cho LLM ch√≠nh"""
        return f"""
NG·ªÆ C·∫¢NH CU·ªòC TR√í CHUY·ªÜN:
{history_summary}

C√ÇU H·ªéI HI·ªÜN T·∫†I:
{current_input}
"""

class GeminiChatbot:
    """Gemini Flash chatbot with Redis memory and intelligent search"""
    
    def __init__(self, memory_manager: RedisMemoryManager, searcher: DuckDuckGoSearcher):
        self.memory = memory_manager
        self.searcher = searcher
        self.model = None
        
        # Initialize Gemini
        api_key = os.getenv('GEMINI_API_KEY')
        if not api_key:
            raise ValueError("GEMINI_API_KEY environment variable is required")
        
        genai.configure(api_key=api_key)
        self.model = genai.GenerativeModel('gemini-2.0-flash')
        
        # Initialize history processor
        self.history_processor = HistoryProcessor(self.model)
        
        logger.info("Gemini Flash model initialized")
    
    async def chat(self, user_id: str, thread_id: str, user_message: str) -> str:
        """Process chat message with intelligent history-aware search"""
        try:
            print("\n" + "="*80)
            print("üîÑ B·∫ÆT ƒê·∫¶U X·ª¨ L√ù CHAT")
            print("="*80)
            
            # Get or create conversation
            conversation = await self.memory.get_conversation(thread_id)
            
            if not conversation:
                conversation = ConversationContext(
                    thread_id=thread_id,
                    user_id=user_id,
                    messages=[],
                    metadata={"model": "gemini-2.0-flash", "search_enabled": True}
                )
            
            # Print user input
            print(f"üìù USER INPUT:")
            print(f"   {user_message}")
            print()
            
            # Print conversation history
            print(f"üìö L·ªäCH S·ª¨ H·ªòI THO·∫†I ({len(conversation.messages)} tin nh·∫Øn):")
            if conversation.messages:
                for i, msg in enumerate(conversation.messages[-5:], 1):  # Show last 5 messages
                    role_icon = "üë§" if msg.role == "user" else "ü§ñ"
                    print(f"   {i}. {role_icon} {msg.role}: {msg.content[:100]}{'...' if len(msg.content) > 100 else ''}")
            else:
                print("   (Ch∆∞a c√≥ l·ªãch s·ª≠)")
            print()
            
            # STEP 1: Process history and current input
            processing_result = await self.history_processor.process_history_and_input(
                conversation.messages, user_message
            )
            
            # STEP 2: Perform search if needed
            search_results_text = ""
            if processing_result['need_search']:
                search_query = processing_result['search_query']
                print(f"üîç ƒêANG T√åM KI·∫æM V·ªöI QUERY: '{search_query}'")
                
                search_results = await self.searcher.search(search_query, max_results=5)
                search_results_text = self.searcher.format_search_results(search_results)
                
                print("üìä K·∫æT QU·∫¢ T√åM KI·∫æM:")
                if search_results:
                    for i, result in enumerate(search_results, 1):
                        print(f"   {i}. {result['title']}")
                        print(f"      Snippet: {result['snippet'][:150]}{'...' if len(result['snippet']) > 150 else ''}")
                        print()
                else:
                    print("   Kh√¥ng t√¨m th·∫•y k·∫øt qu·∫£")
                print()
            
            # STEP 3: Create enhanced prompt
            enhanced_message = self._create_enhanced_prompt(
                processing_result['context_for_llm'],
                user_message,
                search_results_text
            )
            
            # Print final prompt to LLM
            print("ü§ñ PROMPT ƒê∆ØA V√ÄO GEMINI:")
            print("-" * 60)
            print(enhanced_message[:500] + "..." if len(enhanced_message) > 500 else enhanced_message)
            print("-" * 60)
            print()
            
            # Add user message to conversation
            user_msg = ChatMessage(
                role="user", 
                content=user_message,
                search_results=search_results_text if search_results_text else None
            )
            conversation.messages.append(user_msg)
            
            # Prepare conversation history for Gemini
            history = self._prepare_gemini_history(conversation.messages[:-1])
            
            print("‚è≥ ƒêANG G·ª¨I REQUEST ƒê·∫æN GEMINI...")
            
            # Start chat with history
            chat = self.model.start_chat(history=history)
            
            # Send enhanced message and get response
            response = await asyncio.to_thread(chat.send_message, enhanced_message)
            bot_response = response.text
            
            print("‚úÖ NH·∫¨N ƒê∆Ø·ª¢C PH·∫¢N H·ªíI T·ª™ GEMINI:")
            print("-" * 60)
            print(bot_response[:300] + "..." if len(bot_response) > 300 else bot_response)
            print("-" * 60)
            print()
            
            # Add bot message
            bot_msg = ChatMessage(role="assistant", content=bot_response)
            conversation.messages.append(bot_msg)
            
            # Keep only last 20 messages to prevent memory bloat
            if len(conversation.messages) > 20:
                conversation.messages = conversation.messages[-20:]
                print("üóëÔ∏è ƒê√É X√ìA TIN NH·∫ÆN C≈® (GI·ªÆ 20 TIN NH·∫ÆN G·∫¶N NH·∫§T)")
            
            # Save conversation
            await self.memory.save_conversation(conversation)
            print("üíæ ƒê√É LUU CONVERSATION V√ÄO REDIS")
            
            print("="*80)
            print("‚ú® HO√ÄN TH√ÄNH X·ª¨ L√ù CHAT")
            print("="*80)
            
            return bot_response
            
        except Exception as e:
            logger.error(f"Error in chat processing: {e}")
            return f"Xin l·ªói, t√¥i g·∫∑p l·ªói: {str(e)}"
    
    def _create_enhanced_prompt(self, context: str, user_message: str, search_results: str) -> str:
        """T·∫°o prompt t·ªïng h·ª£p cho LLM"""
        prompt_parts = []
        
        # Th√™m context
        prompt_parts.append(f"NG·ªÆ C·∫¢NH CU·ªòC TR√í CHUY·ªÜN:\n{context}")
        
        # Th√™m search results n·∫øu c√≥
        if search_results:
            prompt_parts.append(f"\nTH√îNG TIN T√åM KI·∫æM:\n{search_results}")
        
        # Th√™m instruction
        if search_results:
            instruction = """
H∆Ø·ªöNG D·∫™N TR·∫¢ L·ªúI:
- ∆Øu ti√™n s·ª≠ d·ª•ng th√¥ng tin t·ª´ k·∫øt qu·∫£ t√¨m ki·∫øm n·∫øu li√™n quan
- K·∫øt h·ª£p v·ªõi ng·ªØ c·∫£nh cu·ªôc tr√≤ chuy·ªán ƒë·ªÉ tr·∫£ l·ªùi ch√≠nh x√°c
- N·∫øu th√¥ng tin t√¨m ki·∫øm kh√¥ng ƒë·ªß, h√£y n√≥i r√µ v√† d√πng ki·∫øn th·ª©c c·ªßa b·∫°n
- Tr·∫£ l·ªùi b·∫±ng ti·∫øng Vi·ªát, t·ª± nhi√™n v√† th√¢n thi·ªán
"""
        else:
            instruction = """
H∆Ø·ªöNG D·∫™N TR·∫¢ L·ªúI:
- S·ª≠ d·ª•ng ng·ªØ c·∫£nh cu·ªôc tr√≤ chuy·ªán ƒë·ªÉ tr·∫£ l·ªùi ch√≠nh x√°c
- Tr·∫£ l·ªùi d·ª±a tr√™n ki·∫øn th·ª©c c·ªßa b·∫°n
- Tr·∫£ l·ªùi b·∫±ng ti·∫øng Vi·ªát, t·ª± nhi√™n v√† th√¢n thi·ªán
"""
        
        prompt_parts.append(instruction)
        prompt_parts.append(f"\nC√ÇU H·ªéI: {user_message}")
        
        return "\n".join(prompt_parts)
    
    def _prepare_gemini_history(self, messages: List[ChatMessage]) -> List[Dict]:
        """Convert messages to Gemini chat history format"""
        history = []
        
        for msg in messages:
            # Gemini uses 'user' and 'model' roles
            role = 'user' if msg.role == 'user' else 'model'
            history.append({
                'role': role,
                'parts': [msg.content]
            })
        
        return history

class ChatbotConsole:
    """Console interface for the chatbot"""
    
    def __init__(self):
        self.memory_manager = None
        self.searcher = None
        self.chatbot = None
        self.running = True
        self.thread_id = str(uuid.uuid4())
        self.user_id = "console_user"
        
    def signal_handler(self, signum, frame):
        """Handle Ctrl+C gracefully"""
        print("\n\nüëã T·∫°m bi·ªát! ƒêang tho√°t...")
        self.running = False
    
    async def initialize(self):
        """Initialize chatbot services"""
        try:
            # Setup signal handler for Ctrl+C
            signal.signal(signal.SIGINT, self.signal_handler)
            
            # Initialize memory manager
            self.memory_manager = RedisMemoryManager()
            await self.memory_manager.initialize()
            
            # Initialize searcher
            self.searcher = DuckDuckGoSearcher()
            await self.searcher.initialize()
            
            # Initialize chatbot
            self.chatbot = GeminiChatbot(self.memory_manager, self.searcher)
            
            logger.info("Chatbot initialized successfully")
            
        except Exception as e:
            logger.error(f"Failed to initialize chatbot: {e}")
            raise
    
    async def cleanup(self):
        """Cleanup resources"""
        if self.memory_manager:
            await self.memory_manager.close()
        if self.searcher:
            await self.searcher.close()
    
    def print_welcome(self):
        """Print welcome message"""
        print("=" * 70)
        print("ü§ñ GEMINI FLASH CHATBOT v·ªõi REDIS MEMORY & DUCKDUCKGO SEARCH")
        print("üöÄ N√ÇNG C·∫§P: T√¨m ki·∫øm c√≥ ng·ªØ c·∫£nh (Context-Aware Search)")
        print("=" * 70)
        print("üí° H∆∞·ªõng d·∫´n:")
        print("   ‚Ä¢ Nh·∫≠p tin nh·∫Øn v√† nh·∫•n ENTER ƒë·ªÉ g·ª≠i")
        print("   ‚Ä¢ Nh·∫•n Ctrl+C ƒë·ªÉ tho√°t")
        print("   ‚Ä¢ Bot s·∫Ω t·ª± ƒë·ªông t√¨m ki·∫øm th√¥ng tin khi c·∫ßn thi·∫øt")
        print("   ‚Ä¢ Bot s·∫Ω nh·ªõ l·ªãch s·ª≠ tr√≤ chuy·ªán v√† s·ª≠ d·ª•ng ng·ªØ c·∫£nh cho t√¨m ki·∫øm")
        print(f"   ‚Ä¢ Thread ID: {self.thread_id}")
        print("=" * 70)
        print()
    
    async def run(self):
        """Main chat loop"""
        try:
            await self.initialize()
            self.print_welcome()
            
            while self.running:
                try:
                    # Get user input
                    user_input = input("üë§ B·∫°n: ").strip()
                    
                    if not user_input:
                        continue
                    
                    if not self.running:
                        break
                    
                    # Get bot response (detailed processing will be printed inside)
                    response = await self.chatbot.chat(
                        self.user_id, 
                        self.thread_id, 
                        user_input
                    )
                    
                    # Show final response
                    print(f"üéØ PH·∫¢N H·ªíI CU·ªêI C√ôNG CHO NG∆Ø·ªúI D√ôNG:")
                    print(f"ü§ñ Bot: {response}")
                    print()
                    
                except EOFError:
                    # Handle Ctrl+D
                    break
                except KeyboardInterrupt:
                    # Handle Ctrl+C
                    break
                except Exception as e:
                    print(f"\r‚ùå L·ªói: {e}")
                    print()
            
        except KeyboardInterrupt:
            pass
        finally:
            await self.cleanup()
            print("C·∫£m ∆°n b·∫°n ƒë√£ s·ª≠ d·ª•ng chatbot! üëã")

# Demo function
async def demo():
    """Demo function to test the chatbot"""
    console = ChatbotConsole()
    await console.run()

if __name__ == "__main__":
    # Create .env file or set environment variables:
    """
    REDIS_HOST=localhost
    REDIS_PORT=6379
    REDIS_PASSWORD=
    GEMINI_API_KEY=your_gemini_api_key_here
    """
    
    print("Kh·ªüi ƒë·ªông chatbot v·ªõi t√≠nh nƒÉng t√¨m ki·∫øm...")
    
    try:
        asyncio.run(demo())
    except KeyboardInterrupt:
        print("\nTho√°t chatbot.")
    except Exception as e:
        print(f"L·ªói: {e}")
        sys.exit(1)